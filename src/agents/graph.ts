import { StateGraph, END, START, MemorySaver } from "@langchain/langgraph";
import { echoAgentNode } from "./EchoAgentNode";
import { analysisPrepareNode } from "./AnalysisPrepareNode";
import { analysisInterruptNode } from "./AnalysisInterruptNode";
import { documentRetrievalNode } from "./DocumentRetrievalNode";
import { dbg } from "../utils";

// Define node names as constants
const ECHO_AGENT = "echoAgent";
const ANALYSIS_PREPARE = "analysisPrepare";
const ANALYSIS_INTERRUPT = "analysisInterrupt";
const DOCUMENT_RETRIEVAL = "documentRetrievalNode";

/**
 * Represents the role of a participant in a conversation.
 * - 'user': Represents messages/inputs from the human user
 * - 'agent': Represents responses from the AI agent
 */
export type Role = 'user' | 'agent';

const CMD_ECHO = "echo";

// Define the state interface that will flow through the graph
/**
 * Represents the core application state that flows through the agent graph.
 * This state is passed between nodes and updated during graph execution.
 */
export interface AppState {
    /** The raw input text provided by the user */
    userInput: string;

    /** The latest response generated by an agent node */
    response: string;

    /** Map of file paths to their contents for code analysis */
    fileContents: Record<string, string>;

    /** Map of input file names to their contents, populated by DocumentRetrievalNode */
    inputs: Record<string, string>;

    /** The path to the directory from which to load input files */
    inputDirectoryPath: string;

    /** Conversation history between user and agent during analysis */
    analysisHistory: Array<{ role: Role; content: string }>;

    /** The final analysis output generated by the analysis agent */
    analysisOutput: string;

    /** The current question being asked by the agent during an analysis interrupt */
    currentAnalysisQuery: string;

    /** The name/ID of the LLM model to use for agent interactions */
    modelName: string;
}

function shouldTriggerAnalysis(userInput: string): boolean {
    const analysisKeywords = ["analyze", "analysis", "review requirement", "start analysis"];
    return analysisKeywords.some(keyword => userInput.includes(keyword));
}

// Instantiate the graph
const workflow = new StateGraph<AppState>({
        channels: {
            //save the new user input
            userInput: { value: (currentState, update) => update !== undefined && update !== null ? update : currentState, default: () => "" },   
            response: { value: (x, y) => y, default: () => "" },                                        // Takes new response (used by echo)
            fileContents: { value: (x, y) => y ?? x, default: () => ({}) },                             // Persist, allow override
            inputs: { value: (x, y) => y ?? x, default: () => ({}) }, // Persist, allow override
            analysisHistory: { value: (x, y) => (x || []).concat(y || []), default: () => ([]) },       // Append new messages
            analysisOutput: { value: (x, y) => y, default: () => "" },                                  // Takes new output
            currentAnalysisQuery: { value: (x, y) => y, default: () => "" },                            // Takes new query
            modelName: { value: (x, y) => y ?? x, default: () => "" }, // Item 18: Add channel config
            inputDirectoryPath: { value: (x, y) => y ?? x, default: () => "" },
        },
    })
    .addNode(ECHO_AGENT, echoAgentNode)
    .addNode(ANALYSIS_PREPARE, analysisPrepareNode)
    .addNode(ANALYSIS_INTERRUPT, analysisInterruptNode)
    .addNode(DOCUMENT_RETRIEVAL, documentRetrievalNode)
    
    // Make the conditional edge originate from START
    .addConditionalEdges(START, 
        (state: AppState) => { // Keep synchronous
            
            const userInput = state.userInput.toLowerCase();
            let nextNodeDecision: string;

            // Determine initial routing based on input
            switch (true) {
                case shouldTriggerAnalysis(userInput):
                    nextNodeDecision = DOCUMENT_RETRIEVAL;
                    break;
                case userInput.startsWith(CMD_ECHO):
                    nextNodeDecision = ECHO_AGENT;
                    break;
                default:
                    nextNodeDecision = END;
                    break;
            }
            
            dbg(`Initial Routing Condition: Routing to ${nextNodeDecision}`); // Updated log message
            return nextNodeDecision;
        },
        {
            // Mapping destinations
            [ECHO_AGENT]: ECHO_AGENT,
            [ANALYSIS_PREPARE]: ANALYSIS_PREPARE,
            [DOCUMENT_RETRIEVAL]: DOCUMENT_RETRIEVAL,
            [END]: END,
        }
    )
    .addEdge(DOCUMENT_RETRIEVAL, ANALYSIS_PREPARE)
    .addEdge(ECHO_AGENT, END)
    .addConditionalEdges(ANALYSIS_PREPARE,
        (state: AppState) => { // Keep synchronous 
            if (state.analysisOutput) {
                return END;
            } else {
                return ANALYSIS_INTERRUPT;
            }
        },
        {
            [END]: END,
            [ANALYSIS_INTERRUPT]: ANALYSIS_INTERRUPT
        }
    )
    .addEdge(ANALYSIS_INTERRUPT, ANALYSIS_PREPARE) // After interrupt node, go back to the PREPARE node to process the resumed input
;

const checkpointer = new MemorySaver();
export const app = workflow.compile({ checkpointer }); 